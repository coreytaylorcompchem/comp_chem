import math

import pandas as pd
from chembl_webresource_client.new_client import new_client
from chembl_webresource_client.settings import Settings
from tqdm import tqdm
from typing import List

#   Some parameters to control importation of the data and make sure it arrives

# Decide which protocol to use (HTTP):
Settings.Instance().WEBSERVICE_PROTOCOL = 'http'

# Point client to our local webservices instance
Settings.Instance().WEBSERVICE_DOMAIN = 'localhost'

# And change their prefix:
Settings.Instance().WEBSERVICE_PREFIX = '/ws'

# Root url will look like this:
# 'http://localhost/ws', instead of default:
# 'https://www.ebi.ac.uk/chemblws'

# default request timeout:
Settings.Instance().TIMEOUT = 100
Settings.Instance().CACHING = False  # Caching switched off
Settings.Instance().FAST_SAVE = (
    False  # Fast saving switched off. Slower but data stored in cache won't be corrupted.
)
Settings.Instance().TOTAL_RETRIES = 10
Settings.Instance().CONCURRENT_SIZE = 100
Settings.Instance().MAX_LIMIT = 50  # Set how many molecules to retrieve each request


def retrieve_chembl_bioactivities(uniprot_id: str) -> pd.DataFrame:
    """Script to retrieve target data from ChEMBL.

    A uniprot id for a target is used to generate a QuerySet, which is then used to
    download a dataframe of assay data specific to the target.

    Parameters
    ----------
    uniprot_id : str
        Protein target Uniprot ID

    Returns
    -------
    pd.DataFrame
        Pandas dataframe with assay data for a given target.
    """
    targets_api = new_client.target
    bioactivities_api = new_client.activity

    # Target list generated containing only these parameters.

    targets = targets_api.get(target_components__accession=uniprot_id).only(
        "target_chembl_id", "organism", "pref_name", "target_type"
    )

    targets = pd.DataFrame.from_records(targets)

    target = targets.iloc[0]  # Assume first result is the correct one.
    chembl_id = target.target_chembl_id

    print(f"The target ChEMBL ID is {chembl_id}")

    print("Retrieving bioactivities for ", uniprot_id)

    bioactivities = bioactivities_api.filter(
        target_chembl_id=chembl_id, type="IC50", relation="=", assay_type="B"
    ).only(
        "activity_id",
        "assay_chembl_id",
        "assay_description",
        "assay_type",
        "molecule_chembl_id",
        "type",
        "standard_units",
        "relation",
        "standard_value",
        "target_chembl_id",
        "target_organism",
    )

    print(f"Length and type of bioactivities object: {len(bioactivities)}, {type(bioactivities)}")

    print(f"Length and type of first element: {len(bioactivities[0])}, {type(bioactivities[0])}")

    bioactivities = list(tqdm(bioactivities))  # taking advantage of QuerySet lazy loading.

    bioactivities_df = pd.DataFrame.from_records(bioactivities)

    print(f"DataFrame shape: {bioactivities_df.shape}")

    return bioactivities_df


def cleanup_bioactivities_df(bioactivities_df: pd.DataFrame) -> pd.DataFrame:
    """Cleans and standardises dataframe of bioactivities retrieved from ChEMBL.

    The following operations are performed:

    1. Convert standard_value datatype from object to float
    2. Delete entries with missing values
    3. Keep only entries with standard_unit == nM
    4. Delete duplicate molecules
    5. Rename columns

    Parameters
    ----------
    bioactivities_df : pd.DataFrame
        Pandas dataframe of bioactivities retrieved using retrieve_chembl_bioactivities()

    Returns
    -------
    pd.DataFrame
        Cleaned Pandas dataframe containing retrieved assay data.
    """
    bioactivities_df.dropna(axis=0, how="any", inplace=True)
    print(f"DataFrame shape: {bioactivities_df.shape}")

    print(f"Units in downloaded data: {bioactivities_df['standard_units'].unique()}")
    print(
        f"Number of non-nM entries:\
        {bioactivities_df[bioactivities_df['standard_units'] != 'nM'].shape[0]}"
    )

    bioactivities_df = bioactivities_df[bioactivities_df["standard_units"] == "nM"]
    print(f"Units after filtering: {bioactivities_df['standard_units'].unique()}")

    print(f"DataFrame shape after filtering: {bioactivities_df.shape}")

    # Delete duplicates

    bioactivities_df.drop_duplicates("molecule_chembl_id", keep="first", inplace=True)
    bioactivities_df.reset_index(drop=True, inplace=True)
    print(f"DataFrame shape after removing duplicates: {bioactivities_df.shape}")

    bioactivities_df.rename(
        columns={"standard_value": "IC50", "standard_units": "units"}, inplace=True
    )

    return bioactivities_df


def retrieve_compound_data(bioactivities_df: pd.DataFrame) -> pd.DataFrame:
    """Retrieves compound data associated with bioactivities.

    A bioactivities dataframe is generated by retrieve_chembl_bioactivities().
    A QuerySet is generated with lazy loading, compounds retreieved, pd.nans
    and duplicates are removed and then the dataframe is merged with the
    bioactivity dataframe.

    Parameters
    ----------
    bioactivities_df : pd.DataFrame
        Pandas dataframe of bioactivities retrieved using retrieve_chembl_bioactivities()

    Returns
    -------
    pd.DataFrame
        Dataframe of merged compound and bioactivity data.
    """
    compounds_api = new_client.molecule

    compounds_provider = compounds_api.filter(
        molecule_chembl_id__in=list(bioactivities_df["molecule_chembl_id"])
    ).only("molecule_chembl_id", "molecule_structures")

    print('Downloading', len(compounds_provider), 'compounds from ChEMBL.')

    compounds = list(tqdm(compounds_provider))  # taking advantage of QuerySet lazy loading.

    compounds_df = pd.DataFrame.from_records(
        compounds,
    )
    print(f"Compounds dataframe shape: {compounds_df.shape}")

    # Drop nans

    compounds_df.dropna(axis=0, how="any", inplace=True)
    print(f"Compounds dataFrame shape - nans removed: {compounds_df.shape}")

    # Drop duplicates

    compounds_df.drop_duplicates("molecule_chembl_id", keep="first", inplace=True)
    print(f"Compounds dataFrame shape - duplicates removed: {compounds_df.shape}/n")

    canonical_smiles: List[str] = []

    for i, compounds in compounds_df.iterrows():
        try:
            canonical_smiles.append(compounds["molecule_structures"]["canonical_smiles"])  # type: ignore
        except KeyError:
            canonical_smiles.append(None)

    compounds_df["smiles"] = canonical_smiles
    compounds_df.drop("molecule_structures", axis=1, inplace=True)
    # print(f"Compounds dataframe shape: {compounds_df.shape}")

    compounds_df.dropna(axis=0, how="any", inplace=True)
    # print(f"DataFrame shape: {compounds_df.shape}")

    print("Summary:\n")
    print(f"Total bioactivities after filtering: {bioactivities_df.shape[0]}")
    print(f"Total compounds after filtering: {compounds_df.shape[0]}")

    # Merge DataFrames
    output_df = pd.merge(
        bioactivities_df[["molecule_chembl_id", "IC50", "units"]],
        compounds_df,
        on="molecule_chembl_id",
    )

    # Reset row indices
    output_df.reset_index(drop=True, inplace=True)

    print(f"Final dataset has {output_df.shape[0]} entries.")

    # Apply conversion to each row of the compound DataFrame
    output_df["pIC50"] = output_df.apply(lambda x: convert_ic50_to_pic50(float(x.IC50)), axis=1)

    return output_df


def convert_ic50_to_pic50(IC50_value: float) -> float:
    """Performs a log10 conversion of IC50 values (float)
    to pIC50 (float)

    Parameters
    ----------
    IC50_value : float
        The half maximal inhibitory concentration.

    Returns
    -------
    float
        Log10 conversion of IC50
    """
    pIC50_value = 9 - math.log10(IC50_value)
    return pIC50_value
